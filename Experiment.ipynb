{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "from END import EnsembleND\n",
    "import NestedDichotomies.nd as nd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from PairwiseCoupling import PairwiseCoupling\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Baselearner\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Methods\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Basics\n",
    "import pandas as pd\n",
    "import os\n",
    "from threading import Thread\n",
    "import openml\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brier_score(y_predict, y_test, nclass):\n",
    "    obj_num = np.size(y_test)\n",
    "    bs_ytrue = np.zeros((obj_num,nclass))\n",
    "    for i in range(obj_num):\n",
    "        bs_ytrue[i,y_test[i]]=1\n",
    "    bs = sum(sum((y_predict-bs_ytrue)**2))/obj_num\n",
    "    return bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelcombos.END_DT import EnsembleND_DT as END_DT\n",
    "from modelcombos.END_LR import EnsembleND_LR as END_LR\n",
    "from modelcombos.END_NB import EnsembleND_NB as END_NB\n",
    "from modelcombos.PC_DT import PairwiseCoupling_DT as PC_DT\n",
    "from modelcombos.PC_LR import PairwiseCoupling_LR as PC_LR\n",
    "from modelcombos.PC_NB import PairwiseCoupling_NB as PC_NB\n",
    "def generateModelName(model):\n",
    "    name = 'error'\n",
    "    if (model.__class__==RandomForestClassifier):\n",
    "        name = 'RF'\n",
    "    if (model.__class__==PC_DT):\n",
    "        name = 'PC_DT'\n",
    "    if (model.__class__==PC_LR):\n",
    "        name = 'PC_LR'\n",
    "    if (model.__class__==PC_NB):\n",
    "        name = 'PC_NB'\n",
    "    if (model.__class__==MLPClassifier):\n",
    "        name = 'MLP'\n",
    "    if (model.__class__==END_DT):\n",
    "        name = 'END_DT'\n",
    "    if (model.__class__==END_LR):\n",
    "        name = 'END_LR'\n",
    "    if (model.__class__==END_NB):\n",
    "        name = 'END_NB'\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brier_score_singular_factory(nclass):\n",
    "    #def brier_score_singular(y_test, y_predict):\n",
    "    #    bs_ytrue = np.zeros((nclass))\n",
    "    #    bs_ytrue[y_test]=1\n",
    "    #    bs = sum((y_predict-bs_ytrue)**2)\n",
    "    #    return bs\n",
    "    def brier_score_singular(y_test,y_predict):\n",
    "        #print(y_predict)\n",
    "        #print(y_test)\n",
    "        obj_num = np.size(y_test)\n",
    "        bs_ytrue = np.zeros((obj_num,nclass))\n",
    "        for i in range(obj_num):\n",
    "            bs_ytrue[i,y_test[i]]=1\n",
    "        bs = sum(sum((y_predict-bs_ytrue)**2))/obj_num\n",
    "        return bs\n",
    "    \n",
    "    return brier_score_singular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TMTB_and_ECE(y_predict, y_test, nclass, nbins=10, ccstrat='uniform'):\n",
    "    y_pred_list = np.reshape(y_predict,nclass*y_test.size)\n",
    "    ninst = y_test.size\n",
    "    onehot = np.zeros((ninst, nclass))\n",
    "    onehot[np.arange(ninst), y_test] = 1\n",
    "    y_test_list = np.reshape(onehot,nclass*y_test.size)\n",
    "    prob_true, prob_pred = calibration_curve(y_test_list, y_pred_list, n_bins=nbins, strategy=ccstrat)\n",
    "    ece = np.sum(np.absolute(prob_true-prob_pred))/prob_true.size\n",
    "    return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveCSVofData(path, file_name, data, columns):\n",
    "    df = pd.DataFrame(np.array(data),columns=columns)\n",
    "    df.to_csv(path+file_name+'.csv', sep='\\t', encoding='utf-8', index=False)\n",
    "    \n",
    "def saveResults(dataset_name, bs_byModel_base_run, ece_byModel_base_run, bs_byModel_sig_run, ece_byModel_sig_run, bs_byModel_iso_run, ece_byModel_iso_run, hyperparam_byModel_run, mft_byModel_run, mst_byModel_run):\n",
    "    dir_path = os.getcwd()\n",
    "    directory = dir_path+'/experiments/'+dataset_name+'/result_'+strftime(\"%Y-%m-%d %H_%M_%S\", gmtime())+'/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    models = generate_ModelHyperparam_pairs()\n",
    "    m_names = [generateModelName(models[i][0]) for i in range(len(models))]\n",
    "    saveCSVofData(directory,'brier_base', bs_byModel_base_run, m_names)\n",
    "    saveCSVofData(directory,'ece_base', ece_byModel_base_run, m_names)\n",
    "    saveCSVofData(directory,'brier_sigmoid', bs_byModel_sig_run, m_names)\n",
    "    saveCSVofData(directory,'ece_sigmoid', ece_byModel_sig_run, m_names)\n",
    "    saveCSVofData(directory,'brier_isotonic', bs_byModel_iso_run, m_names)\n",
    "    saveCSVofData(directory,'ece_isotonic', ece_byModel_iso_run, m_names)\n",
    "    saveCSVofData(directory,'hyperparameter', hyperparam_byModel_run, m_names)\n",
    "    saveCSVofData(directory,'mean_fit_time', mft_byModel_run, m_names)\n",
    "    saveCSVofData(directory,'mean_score_time', mst_byModel_run, m_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Compare all models\n",
    "def CompareModels(data_X, data_y, n_runs=1, n_jobs=1):\n",
    "    seed = 2000\n",
    "    num_classes = np.unique(data_y).size\n",
    "    # for each run the brierscore for each model [no calibration]\n",
    "    bs_byModel_base_run = []\n",
    "    # for each run the ece (expected calibration error) for each model [no calibration]\n",
    "    ece_byModel_base_run = []\n",
    "    # for each run the brierscore for each model [sigmoid calibration]\n",
    "    bs_byModel_sig_run = []\n",
    "    # for each run the ece (expected calibration error) for each model [sigmoid calibration]\n",
    "    ece_byModel_sig_run = []\n",
    "    # for each run the brierscore for each model [isotonic calibration]\n",
    "    bs_byModel_iso_run = []\n",
    "    # for each run the ece (expected calibration error) for each model [isotonic calibration]\n",
    "    ece_byModel_iso_run = []\n",
    "    # for each run the hyperparameter for each model\n",
    "    hyperparam_byModel_run = []\n",
    "    # for each run the mean fit time for each model\n",
    "    mft_byModel_run = []\n",
    "    # for each run the mean score time for each model\n",
    "    mst_byModel_run = []\n",
    "    # RUNS\n",
    "    for i in range(n_runs):\n",
    "        print('run',i+1)\n",
    "        bs_byModel_base_run.append([])\n",
    "        ece_byModel_base_run.append([])\n",
    "        bs_byModel_sig_run.append([])\n",
    "        ece_byModel_sig_run.append([])\n",
    "        bs_byModel_iso_run.append([])\n",
    "        ece_byModel_iso_run.append([])\n",
    "        hyperparam_byModel_run.append([])\n",
    "        mft_byModel_run.append([])\n",
    "        mst_byModel_run.append([])\n",
    "        # train - test von data (80/20)\n",
    "        X_train, X_test, y_train, y_test = tts(data_X, data_y, test_size=0.2, stratify=data_y, random_state=seed)\n",
    "        # model - calibration split von train (70/30)\n",
    "        X_model, X_calibration, y_model, y_calibration = tts(X_train, y_train, test_size=0.3, stratify=y_train, random_state=seed+1)\n",
    "        \n",
    "        scoring = {'bs': make_scorer(brier_score_singular_factory(num_classes), greater_is_better=False, needs_proba=True)}\n",
    "        \n",
    "        model_dists = generate_ModelHyperparam_pairs(num_classes, seed)\n",
    "        \n",
    "        for k in range(len(model_dists)):\n",
    "            print('model',k+1)\n",
    "            #if (k==1):\n",
    "            #    set_trace()\n",
    "            model_rs = RandomizedSearchCV(model_dists[k][0], param_distributions=model_dists[k][1], scoring=scoring,refit='bs', n_iter = 10, n_jobs = n_jobs, cv=3, random_state=seed)\n",
    "            model_rs.fit(X_model, y_model)\n",
    "            print('mean fit time:',model_rs.cv_results_['mean_fit_time'].mean())\n",
    "            print('mean score time:',model_rs.cv_results_['mean_score_time'].mean())\n",
    "            seed += 1\n",
    "            print(model_rs.best_params_)\n",
    "            # best estimator\n",
    "            hyperparam_byModel_run[i].append(model_rs.best_params_)\n",
    "            model = model_rs.best_estimator_\n",
    "            #calibration sigmoid\n",
    "            c_sig_model = CalibratedClassifierCV(base_estimator=model,method='sigmoid', cv='prefit')\n",
    "            c_sig_model.fit(X_calibration, y_calibration)\n",
    "            #calibration isotonic\n",
    "            c_iso_model = CalibratedClassifierCV(base_estimator=model,method='isotonic', cv='prefit')\n",
    "            c_iso_model.fit(X_calibration, y_calibration)\n",
    "            #prediction base\n",
    "            y_pred_base = model.predict_proba(X_test)\n",
    "            bs_base = brier_score(y_predict=y_pred_base, y_test=y_test, nclass=num_classes)\n",
    "            ece_base = TMTB_and_ECE(y_predict=y_pred_base, y_test=y_test, nclass=num_classes, nbins=10, ccstrat='uniform')\n",
    "            #prediction sigmoid calibrated model\n",
    "            y_pred_sig = c_sig_model.predict_proba(X_test)\n",
    "            bs_sig = brier_score(y_predict=y_pred_sig, y_test=y_test, nclass=num_classes)\n",
    "            ece_sig = TMTB_and_ECE(y_predict=y_pred_sig, y_test=y_test, nclass=num_classes, nbins=10, ccstrat='uniform')\n",
    "            #prediction isotonic calibrated model\n",
    "            y_pred_iso = c_iso_model.predict_proba(X_test)\n",
    "            bs_iso = brier_score(y_predict=y_pred_iso, y_test=y_test, nclass=num_classes)\n",
    "            ece_iso = TMTB_and_ECE(y_predict=y_pred_iso, y_test=y_test, nclass=num_classes, nbins=10, ccstrat='uniform')\n",
    "            #append results\n",
    "            bs_byModel_base_run[i].append(bs_base)\n",
    "            ece_byModel_base_run[i].append(ece_base)\n",
    "            bs_byModel_sig_run[i].append(bs_sig)\n",
    "            ece_byModel_sig_run[i].append(ece_sig)\n",
    "            bs_byModel_iso_run[i].append(bs_iso)\n",
    "            ece_byModel_iso_run[i].append(ece_iso)\n",
    "            mft_byModel_run[i].append(model_rs.cv_results_['mean_fit_time'].mean())\n",
    "            mst_byModel_run[i].append(model_rs.cv_results_['mean_score_time'].mean())\n",
    "            print(bs_base,ece_base,bs_sig, ece_sig, bs_iso, ece_iso)\n",
    "    return bs_byModel_base_run, ece_byModel_base_run, bs_byModel_sig_run, ece_byModel_sig_run, bs_byModel_iso_run, ece_byModel_iso_run, hyperparam_byModel_run, mft_byModel_run, mst_byModel_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelcombos.END_DT import EnsembleND_DT as END_DT\n",
    "from modelcombos.END_LR import EnsembleND_LR as END_LR\n",
    "from modelcombos.END_NB import EnsembleND_NB as END_NB\n",
    "from modelcombos.PC_DT import PairwiseCoupling_DT as PC_DT\n",
    "from modelcombos.PC_LR import PairwiseCoupling_LR as PC_LR\n",
    "from modelcombos.PC_NB import PairwiseCoupling_NB as PC_NB\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "def generate_ModelHyperparam_pairs(nclasses=3, seed=42):\n",
    "    models = []\n",
    "    RFC_paramdist =  {\n",
    "        'min_impurity_decrease': uniform(0.00001, 0.1),\n",
    "        'min_samples_leaf': randint(1,51)}\n",
    "    models.append((RandomForestClassifier(n_estimators=45, random_state=seed), RFC_paramdist))\n",
    "    DT_paramdist = {\n",
    "        'max_depth': randint(1,4)\n",
    "    }\n",
    "    LR_paramdist = {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': uniform(0.01,20)\n",
    "    }\n",
    "    NB_paramdist = {\n",
    "        'var_smoothing' : uniform(0.0000000001,1.0)\n",
    "    }\n",
    "    models.append((END_DT(number_of_nds=5, number_of_classes=nclasses, max_depth = 1, generator_String='random_pair', random_state=seed), DT_paramdist))\n",
    "    models.append((END_LR(number_of_nds=5, number_of_classes=nclasses,penalty='l2', C=1.0, generator_String='random_pair', random_state=seed), LR_paramdist))\n",
    "    models.append((END_NB(number_of_nds=5, number_of_classes=nclasses, var_smoothing=0.00001, generator_String='random_pair', random_state=seed),NB_paramdist))\n",
    "    models.append((PC_DT(classes=nclasses, seed=seed, max_depth=1),DT_paramdist))\n",
    "    models.append((PC_LR(classes=nclasses, seed=seed, penalty='l2', C=1.0),LR_paramdist))\n",
    "    models.append((PC_NB(classes=nclasses, seed=seed, var_smoothing=0.0001),NB_paramdist))\n",
    "    MLP_paramdist = {\n",
    "        'alpha': uniform(0.00000001, 10),\n",
    "        'batch_size': [100,200,300,400,500],\n",
    "        'power_t': uniform(0.001,5) \n",
    "    }\n",
    "    models.append((MLPClassifier(hidden_layer_sizes = (35,), activation='logistic', learning_rate='invscaling'), MLP_paramdist))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "    \n",
    "def write_single_value_per_run(file, models, value_name, values):\n",
    "    file.write(value_name+'\\n')\n",
    "    file.write(generateModelName(models[0][0]))\n",
    "    for i in range(len(models)-1):\n",
    "        file.write('\\t'+generateModelName(models[i+1][0]))\n",
    "    file.write('\\n')\n",
    "    for i in range(len(values)):\n",
    "        file.write(str(values[i][0]))\n",
    "        for k in range(len(values[i])-1):\n",
    "            file.write('\\t'+str(values[i][k+1]))\n",
    "        file.write('\\n')\n",
    "    \n",
    "def save_result(dataset_id, nclasses, bs_byModel_base_run, ece_byModel_base_run, bs_byModel_sig_run, ece_byModel_sig_run, bs_byModel_iso_run, ece_byModel_iso_run, hyperparam_byModel_run, mft_byModel_run, mst_byModel_run):\n",
    "    dir_path = os.getcwd()\n",
    "    directory = dir_path+'/experiments/'+dataset_id+'/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    models = generate_ModelHyperparam_pairs(nclasses=nclasses, seed=42)\n",
    "    file = open(directory+'result_'+strftime(\"%Y-%m-%d %H_%M_%S\", gmtime())+'.txt', 'w')\n",
    "    # WRITE MODEL DESCRIPTIONS\n",
    "    try:\n",
    "        # SAVING BRIER SCORE\n",
    "        file.write('Brier-Score\\n')\n",
    "        file.write(generateModelName(models[0][0]))\n",
    "        for i in range(len(models)-1):\n",
    "            file.write('\\t\\t\\t'+generateModelName(models[i+1][0]))\n",
    "        file.write('\\nBase\\tSigmoid\\tIsotonic')\n",
    "        for i in range(len(models)-1):\n",
    "            file.write('\\tBase\\tSigmoid\\tIsotonic')\n",
    "        file.write('\\n')\n",
    "        for i in range(len(bs_byModel_base_run)):\n",
    "            file.write(str(bs_byModel_base_run[i][0])+'\\t'+str(bs_byModel_sig_run[i][0])+'\\t'+str(bs_byModel_iso_run[i][0]))\n",
    "            for k in range(len(bs_byModel_base_run[i])-1):\n",
    "                file.write('\\t'+str(bs_byModel_base_run[i][k+1])+'\\t'+str(bs_byModel_sig_run[i][k+1])+'\\t'+str(bs_byModel_iso_run[i][k+1]))\n",
    "            file.write('\\n')\n",
    "        # SAVING ECE SCORE\n",
    "        file.write('ECE-Score\\n')\n",
    "        file.write(generateModelName(models[0][0]))\n",
    "        for i in range(len(models)-1):\n",
    "            file.write('\\t\\t\\t'+generateModelName(models[i+1][0]))\n",
    "        file.write('\\nBase\\tSigmoid\\tIsotonic')\n",
    "        for i in range(len(models)-1):\n",
    "            file.write('\\tBase\\tSigmoid\\tIsotonic')\n",
    "        file.write('\\n')\n",
    "        for i in range(len(ece_byModel_base_run)):\n",
    "            file.write(str(ece_byModel_base_run[i][0])+'\\t'+str(ece_byModel_sig_run[i][0])+'\\t'+str(ece_byModel_iso_run[i][0]))\n",
    "            for k in range(len(ece_byModel_base_run[i])-1):\n",
    "                file.write('\\t'+str(ece_byModel_base_run[i][k+1])+'\\t'+str(ece_byModel_sig_run[i][k+1])+'\\t'+str(ece_byModel_iso_run[i][k+1]))\n",
    "            file.write('\\n')\n",
    "        # SAVING HYPERPARAMETER\n",
    "        write_single_value_per_run(file, models, 'Hyperparameter', hyperparam_byModel_run)\n",
    "        # SAVING MEAN FIT TIME\n",
    "        write_single_value_per_run(file, models, 'Mean Fit Time', mft_byModel_run)\n",
    "        # SAVING MEAN SCORE TIME\n",
    "        write_single_value_per_run(file, models, 'Mean Score Time', mst_byModel_run)\n",
    "    finally:\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1515 - micro-mass\n",
    "#1459 - artificial-characters\n",
    "#1233 - eating\n",
    "#1569 - poker-hand\n",
    "#1503 - spoken-arabic-digit\n",
    "#4541 - Diabetes130US\n",
    "#4538 - GesturePhaseSegmentationProcessed\n",
    "#41991 - Kuzushiji-49 - error\n",
    "#40670 - dna\n",
    "#1478 - har\n",
    "#40984 - segment\n",
    "#40498 - wine-quality-white\n",
    "#40499 - texture\n",
    "#40686 - solar-flare\n",
    "#41972 - Indian_pines\n",
    "#1475 - first-order-theorem-proving\n",
    "#id_list = [1515,1459,1233,1569,1503,4541,4538,41991,40670,1478,40984,40498,40499,40686,41972,1475]\n",
    "#for i in range(len(id_list)):\n",
    "#    ID_n = id_list[i]\n",
    "#    RUNS_n = 20\n",
    "#    JOBS_n = 10\n",
    "#    run_dataset(ID_n, RUNS_n, JOBS_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start experiment\n",
    "def run_dataset(ID, RUNS, JOBS):\n",
    "    dataset = openml.datasets.get_dataset(ID)\n",
    "    dataset_name = dataset.name\n",
    "    dataset_id = dataset.dataset_id\n",
    "    print(dataset_name, 'id: ', dataset_id)\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(dataset_format='array', target=dataset.default_target_attribute)\n",
    "    print(np.unique(y))\n",
    "    num_classes = np.unique(y).size\n",
    "    #bs & ece for (b)ase, (s)igmoid and (i)sotonic\n",
    "    bs_b, ece_b, bs_s, ece_s, bs_i, ece_i, hyppar, mft, mst = CompareModels(data_X=X, data_y=y, n_runs=RUNS, n_jobs=JOBS)\n",
    "    saveResults(dataset_id=dataset_id, bs_byModel_base_run=bs_b, ece_byModel_base_run=ece_b, bs_byModel_sig_run=bs_s, ece_byModel_sig_run=ece_s, bs_byModel_iso_run=bs_i, ece_byModel_iso_run=ece_i, hyperparam_byModel_run=hyppar, mft_byModel_run=mft, mst_byModel_run=mst)\n",
    "    #save_result(dataset_name=dataset_name, nclasses=num_classes, bs_byModel_base_run=bs_b, ece_byModel_base_run=ece_b, bs_byModel_sig_run=bs_s, ece_byModel_sig_run=ece_s, bs_byModel_iso_run=bs_i, ece_byModel_iso_run=ece_i, hyperparam_byModel_run=hyppar, mft_byModel_run=mft, mst_byModel_run=mst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro-mass\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "run 1\n",
      "model 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-304d8738454b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mRUNS_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mJOBS_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mrun_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mID_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRUNS_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJOBS_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-b236b57ed2b8>\u001b[0m in \u001b[0;36mrun_dataset\u001b[1;34m(ID, RUNS, JOBS)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#bs & ece for (b)ase, (s)igmoid and (i)sotonic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mbs_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mece_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbs_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mece_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbs_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mece_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyppar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCompareModels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_runs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRUNS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mJOBS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0msaveResults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbs_byModel_base_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mece_byModel_base_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mece_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbs_byModel_sig_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mece_byModel_sig_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mece_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbs_byModel_iso_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mece_byModel_iso_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mece_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyperparam_byModel_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyppar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmft_byModel_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmst_byModel_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#save_result(dataset_name=dataset_name, nclasses=num_classes, bs_byModel_base_run=bs_b, ece_byModel_base_run=ece_b, bs_byModel_sig_run=bs_s, ece_byModel_sig_run=ece_s, bs_byModel_iso_run=bs_i, ece_byModel_iso_run=ece_i, hyperparam_byModel_run=hyppar, mft_byModel_run=mft, mst_byModel_run=mst)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-66e347139fbb>\u001b[0m in \u001b[0;36mCompareModels\u001b[1;34m(data_X, data_y, n_runs, n_jobs)\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;31m#    set_trace()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mmodel_rs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dists\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_dists\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mmodel_rs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mean fit time:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_rs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_fit_time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mean score time:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_rs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_score_time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    685\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1466\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1467\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1468\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    664\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 666\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "id_list = [1515,1459,1233,1569,1503,4541,4538,40670,1478,40984,40498,40499,40686,41972,1475,40474,1565,1559,1568,1560,40668,11,62,2,1557,4153,40975,61,300,1509]\n",
    "for i in range(0,len(id_list)):\n",
    "    ID_n = id_list[i]\n",
    "    RUNS_n = 20\n",
    "    JOBS_n = 10\n",
    "    run_dataset(ID_n, RUNS_n, JOBS_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "micro-mass 1515\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "artificial-characters 1459\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "eating 1233\n",
      "[0 1 2 3 4 5 6]\n",
      "poker-hand 1569\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "spoken-arabic-digit 1503\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "Diabetes130US 4541\n",
      "[0 1 2]\n",
      "GesturePhaseSegmentationProcessed 4538\n",
      "[0 1 2 3 4]\n",
      "dna 40670\n",
      "[0 1 2]\n",
      "har 1478\n",
      "[0 1 2 3 4 5]\n",
      "segment 40984\n",
      "[0 1 2 3 4 5 6]\n",
      "wine-quality-white 40498\n",
      "[0 1 2 3 4 5 6]\n",
      "texture 40499\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "solar-flare 40686\n",
      "[0 1 2 3 4]\n",
      "Indian_pines 41972\n",
      "[0 1 2 3 4 5 6 7]\n",
      "first-order-theorem-proving 1475\n",
      "[0 1 2 3 4 5]\n",
      "thyroid-allbp 40474\n",
      "[0 1 2 3 4]\n",
      "heart-h 1565\n",
      "[0 1 2 3 4]\n",
      "breast-tissue 1559\n",
      "[0 1 2 3]\n",
      "nursery 1568\n",
      "[0 1 2 3]\n",
      "cardiotocography 1560\n",
      "[0 1 2]\n",
      "connect-4 40668\n",
      "[0 1 2]\n",
      "balance-scale 11\n",
      "[0 1 2]\n",
      "zoo 62\n",
      "[0 1 2 3 4 5 6]\n",
      "anneal 2\n",
      "[0 1 2 4 5]\n",
      "abalone 1557\n",
      "[0 1 2]\n",
      "Smartphone-Based_Recognition_of_Human_Activities 4153\n",
      "[0 1 2 3 4 5]\n",
      "car 40975\n",
      "[0 1 2 3]\n",
      "iris 61\n",
      "[0 1 2]\n",
      "isolet 300\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25]\n",
      "walking-activity 1509\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n"
     ]
    }
   ],
   "source": [
    "id_list = [1515,1459,1233,1569,1503,4541,4538,40670,1478,40984,40498,40499,40686,41972,1475,40474,1565,1559,1568,1560,40668,11,62,2,1557,4153,40975,61,300,1509]\n",
    "print(len(id_list))\n",
    "print(len(np.unique(id_list)))\n",
    "for i in range(0,len(id_list)):\n",
    "    dataset = openml.datasets.get_dataset(id_list[i])\n",
    "    dataset_name = dataset.name\n",
    "    dataset_id = dataset.dataset_id\n",
    "    print(dataset_name, dataset_id)\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(dataset_format='array', target=dataset.default_target_attribute)\n",
    "    print(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
