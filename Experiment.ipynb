{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "from END import EnsembleND\n",
    "import NestedDichotomies.nd as nd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from PairwiseCoupling import PairwiseCoupling\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Baselearner\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Methods\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Basics\n",
    "import os\n",
    "from threading import Thread\n",
    "import openml\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brier_score(y_predict, y_test, nclass):\n",
    "    obj_num = np.size(y_test)\n",
    "    bs_ytrue = np.zeros((obj_num,nclass))\n",
    "    for i in range(obj_num):\n",
    "        bs_ytrue[i,y_test[i]]=1\n",
    "    bs = sum(sum((y_predict-bs_ytrue)**2))/obj_num\n",
    "    return bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelcombos.END_DT import EnsembleND_DT as END_DT\n",
    "from modelcombos.END_LR import EnsembleND_LR as END_LR\n",
    "from modelcombos.END_NB import EnsembleND_NB as END_NB\n",
    "from modelcombos.PC_DT import PairwiseCoupling_DT as PC_DT\n",
    "from modelcombos.PC_LR import PairwiseCoupling_LR as PC_LR\n",
    "from modelcombos.PC_NB import PairwiseCoupling_NB as PC_NB\n",
    "def generateModelName(model):\n",
    "    name = 'error'\n",
    "    if (model.__class__==RandomForestClassifier):\n",
    "        name = 'RF'\n",
    "    if (model.__class__==PC_DT):\n",
    "        name = 'PC_DT'\n",
    "    if (model.__class__==PC_LR):\n",
    "        name = 'PC_LR'\n",
    "    if (model.__class__==PC_NB):\n",
    "        name = 'PC_NB'\n",
    "    if (model.__class__==MLPClassifier):\n",
    "        name = 'MLP'\n",
    "    if (model.__class__==END_DT):\n",
    "        name = 'END_DT'\n",
    "    if (model.__class__==END_LR):\n",
    "        name = 'END_LR'\n",
    "    if (model.__class__==END_NB):\n",
    "        name = 'END_NB'\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brier_score_singular_factory(nclass):\n",
    "    #def brier_score_singular(y_test, y_predict):\n",
    "    #    bs_ytrue = np.zeros((nclass))\n",
    "    #    bs_ytrue[y_test]=1\n",
    "    #    bs = sum((y_predict-bs_ytrue)**2)\n",
    "    #    return bs\n",
    "    def brier_score_singular(y_test,y_predict):\n",
    "        #print(y_predict)\n",
    "        #print(y_test)\n",
    "        obj_num = np.size(y_test)\n",
    "        bs_ytrue = np.zeros((obj_num,nclass))\n",
    "        for i in range(obj_num):\n",
    "            bs_ytrue[i,y_test[i]]=1\n",
    "        bs = sum(sum((y_predict-bs_ytrue)**2))/obj_num\n",
    "        return bs\n",
    "    \n",
    "    return brier_score_singular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TMTB_and_ECE(y_predict, y_test, nclass, nbins=10, ccstrat='uniform'):\n",
    "    y_pred_list = np.reshape(y_predict,nclass*y_test.size)\n",
    "    ninst = y_test.size\n",
    "    onehot = np.zeros((ninst, nclass))\n",
    "    onehot[np.arange(ninst), y_test] = 1\n",
    "    y_test_list = np.reshape(onehot,nclass*y_test.size)\n",
    "    prob_true, prob_pred = calibration_curve(y_test_list, y_pred_list, n_bins=nbins, strategy=ccstrat)\n",
    "    ece = np.sum(np.absolute(prob_true-prob_pred))/prob_true.size\n",
    "    return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating\n"
     ]
    }
   ],
   "source": [
    "#1515 - micro-mass\n",
    "#1459 - artificial-characters\n",
    "#1233 - eating\n",
    "#1569 - poker-hand\n",
    "dataset = openml.datasets.get_dataset(1233)\n",
    "dataset_name = dataset.name\n",
    "print(dataset_name)\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(dataset_format='array', target=dataset.default_target_attribute)\n",
    "num_classes = np.unique(y).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Compare all models\n",
    "def CompareModels(data_X, data_y):\n",
    "    seed = 1000\n",
    "    num_classes = np.unique(data_y).size\n",
    "    # for each run the brierscore for each model [no calibration]\n",
    "    bs_byModel_base_run = []\n",
    "    # for each run the ece (expected calibration error) for each model [no calibration]\n",
    "    ece_byModel_base_run = []\n",
    "    # for each run the brierscore for each model [sigmoid calibration]\n",
    "    bs_byModel_sig_run = []\n",
    "    # for each run the ece (expected calibration error) for each model [sigmoid calibration]\n",
    "    ece_byModel_sig_run = []\n",
    "    # for each run the brierscore for each model [isotonic calibration]\n",
    "    bs_byModel_iso_run = []\n",
    "    # for each run the ece (expected calibration error) for each model [isotonic calibration]\n",
    "    ece_byModel_iso_run = []\n",
    "    # for each run the hyperparameter for each model\n",
    "    hyperparam_byModel_run = []\n",
    "    # RUNS\n",
    "    for i in range(20):\n",
    "        print('run',i+1)\n",
    "        bs_byModel_base_run.append([])\n",
    "        ece_byModel_base_run.append([])\n",
    "        bs_byModel_sig_run.append([])\n",
    "        ece_byModel_sig_run.append([])\n",
    "        bs_byModel_iso_run.append([])\n",
    "        ece_byModel_iso_run.append([])\n",
    "        hyperparam_byModel_run.append([])\n",
    "        # train - test von data (80/20)\n",
    "        X_train, X_test, y_train, y_test = tts(data_X, data_y, test_size=0.2, stratify=data_y, random_state=seed)\n",
    "        # model - calibration split von train (70/30)\n",
    "        X_model, X_calibration, y_model, y_calibration = tts(X_train, y_train, test_size=0.3, stratify=y_train, random_state=seed+1)\n",
    "        \n",
    "        scoring = {'bs': make_scorer(brier_score_singular_factory(num_classes), greater_is_better=False, needs_proba=True)}\n",
    "        \n",
    "        model_dists = generate_ModelHyperparam_pairs(num_classes, seed)\n",
    "        \n",
    "        for k in range(len(model_dists)):\n",
    "            print('model',k+1)\n",
    "            #if (k==1):\n",
    "            #    set_trace()\n",
    "            model_rs = RandomizedSearchCV(model_dists[k][0], param_distributions=model_dists[k][1], scoring=scoring,refit='bs', n_iter = 10, n_jobs = 3, cv=3, random_state=seed)\n",
    "            model_rs.fit(X_model, y_model)\n",
    "            \n",
    "            seed += 1\n",
    "            print(model_rs.best_params_)\n",
    "            # best estimator\n",
    "            hyperparam_byModel_run[i].append(model_rs.best_params_)\n",
    "            model = model_rs.best_estimator_\n",
    "            #calibration sigmoid\n",
    "            c_sig_model = CalibratedClassifierCV(base_estimator=model,method='sigmoid', cv='prefit')\n",
    "            c_sig_model.fit(X_calibration, y_calibration)\n",
    "            #calibration isotonic\n",
    "            c_iso_model = CalibratedClassifierCV(base_estimator=model,method='isotonic', cv='prefit')\n",
    "            c_iso_model.fit(X_calibration, y_calibration)\n",
    "            #prediction base\n",
    "            y_pred_base = model.predict_proba(X_test)\n",
    "            bs_base = brier_score(y_predict=y_pred_base, y_test=y_test, nclass=num_classes)\n",
    "            ece_base = TMTB_and_ECE(y_predict=y_pred_base, y_test=y_test, nclass=num_classes, nbins=10, ccstrat='uniform')\n",
    "            #prediction sigmoid calibrated model\n",
    "            y_pred_sig = c_sig_model.predict_proba(X_test)\n",
    "            bs_sig = brier_score(y_predict=y_pred_sig, y_test=y_test, nclass=num_classes)\n",
    "            ece_sig = TMTB_and_ECE(y_predict=y_pred_sig, y_test=y_test, nclass=num_classes, nbins=10, ccstrat='uniform')\n",
    "            #prediction isotonic calibrated model\n",
    "            y_pred_iso = c_iso_model.predict_proba(X_test)\n",
    "            bs_iso = brier_score(y_predict=y_pred_iso, y_test=y_test, nclass=num_classes)\n",
    "            ece_iso = TMTB_and_ECE(y_predict=y_pred_iso, y_test=y_test, nclass=num_classes, nbins=10, ccstrat='uniform')\n",
    "            #append results\n",
    "            bs_byModel_base_run[i].append(bs_base)\n",
    "            ece_byModel_base_run[i].append(ece_base)\n",
    "            bs_byModel_sig_run[i].append(bs_sig)\n",
    "            ece_byModel_sig_run[i].append(ece_sig)\n",
    "            bs_byModel_iso_run[i].append(bs_iso)\n",
    "            ece_byModel_iso_run[i].append(ece_iso)\n",
    "            print(bs_base,ece_base,bs_sig, ece_sig, bs_iso, ece_iso)\n",
    "    return bs_byModel_base_run, ece_byModel_base_run, bs_byModel_sig_run, ece_byModel_sig_run, bs_byModel_iso_run, ece_byModel_iso_run, hyperparam_byModel_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelcombos.END_DT import EnsembleND_DT as END_DT\n",
    "from modelcombos.END_LR import EnsembleND_LR as END_LR\n",
    "from modelcombos.END_NB import EnsembleND_NB as END_NB\n",
    "from modelcombos.PC_DT import PairwiseCoupling_DT as PC_DT\n",
    "from modelcombos.PC_LR import PairwiseCoupling_LR as PC_LR\n",
    "from modelcombos.PC_NB import PairwiseCoupling_NB as PC_NB\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "def generate_ModelHyperparam_pairs(nclasses, seed):\n",
    "    models = []\n",
    "    RFC_paramdist =  {\n",
    "        'min_impurity_decrease': uniform(0.00001, 0.1),\n",
    "        'min_samples_leaf': randint(1,51)}\n",
    "    models.append((RandomForestClassifier(n_estimators=45, random_state=seed), RFC_paramdist))\n",
    "    DT_paramdist = {\n",
    "        'max_depth': randint(1,4)\n",
    "    }\n",
    "    LR_paramdist = {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': uniform(0.01,20)\n",
    "    }\n",
    "    NB_paramdist = {\n",
    "        'var_smoothing' : uniform(0.0000000001,1.0)\n",
    "    }\n",
    "    models.append((END_DT(number_of_nds=5, number_of_classes=nclasses, max_depth = 1, generator_String='random_pair', random_state=seed), DT_paramdist))\n",
    "    models.append((END_LR(number_of_nds=5, number_of_classes=nclasses,penalty='l2', C=1.0, generator_String='random_pair', random_state=seed), LR_paramdist))\n",
    "    models.append((END_NB(number_of_nds=5, number_of_classes=nclasses, var_smoothing=0.00001, generator_String='random_pair', random_state=seed),NB_paramdist))\n",
    "    models.append((PC_DT(classes=nclasses, seed=seed, max_depth=1),DT_paramdist))\n",
    "    models.append((PC_LR(classes=nclasses, seed=seed, penalty='l2', C=1.0),LR_paramdist))\n",
    "    models.append((PC_NB(classes=nclasses, seed=seed, var_smoothing=0.0001),NB_paramdist))\n",
    "    MLP_paramdist = {\n",
    "        'alpha': uniform(0.00000001, 10),\n",
    "        'batch_size': [100,200,300,400,500],\n",
    "        'power_t': uniform(0.001,5) \n",
    "    }\n",
    "    models.append((MLPClassifier(hidden_layer_sizes = (35,), activation='logistic', learning_rate='invscaling'), MLP_paramdist))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "    \n",
    "def save_result(dataset_name, nclasses, bs_byModel_base_run, ece_byModel_base_run, bs_byModel_sig_run, ece_byModel_sig_run, bs_byModel_iso_run, ece_byModel_iso_run, hyperparam_byModel_run):\n",
    "    dir_path = os.getcwd()\n",
    "    directory = dir_path+'/experiments/'+dataset_name+'/'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    models = generate_ModelHyperparam_pairs(nclasses=nclasses, seed=42)\n",
    "    file = open(directory+'result_'+strftime(\"%Y-%m-%d %H_%M_%S\", gmtime())+'.txt', 'w')\n",
    "    # WRITE MODEL DESCRIPTIONS\n",
    "    try:\n",
    "        # SAVING BRIER SCORE\n",
    "        file.write('Brier-Score\\n')\n",
    "        file.write(generateModelName(models[0][0]))\n",
    "        for i in range(len(models)-1):\n",
    "            file.write('\\t\\t\\t'+generateModelName(models[i+1][0]))\n",
    "        file.write('\\nBase\\tSigmoid\\tIsotonic')\n",
    "        for i in range(len(models)-1):\n",
    "            file.write('\\tBase\\tSigmoid\\tIsotonic')\n",
    "        file.write('\\n')\n",
    "        for i in range(len(bs_byModel_base_run)):\n",
    "            file.write(str(bs_byModel_base_run[i][0])+'\\t'+str(bs_byModel_sig_run[i][0])+'\\t'+str(bs_byModel_iso_run[i][0]))\n",
    "            for k in range(len(bs_byModel_base_run[i])-1):\n",
    "                file.write('\\t'+str(bs_byModel_base_run[i][k+1])+'\\t'+str(bs_byModel_sig_run[i][k+1])+'\\t'+str(bs_byModel_iso_run[i][k+1]))\n",
    "            file.write('\\n')\n",
    "        # SAVING ECE SCORE\n",
    "        file.write('ECE-Score\\n')\n",
    "        file.write(generateModelName(models[0][0]))\n",
    "        for i in range(len(models)-1):\n",
    "            file.write('\\t\\t\\t'+generateModelName(models[i+1][0]))\n",
    "        file.write('\\nBase\\tSigmoid\\tIsotonic')\n",
    "        for i in range(len(models)-1):\n",
    "            file.write('\\tBase\\tSigmoid\\tIsotonic')\n",
    "        file.write('\\n')\n",
    "        for i in range(len(ece_byModel_base_run)):\n",
    "            file.write(str(ece_byModel_base_run[i][0])+'\\t'+str(ece_byModel_sig_run[i][0])+'\\t'+str(ece_byModel_iso_run[i][0]))\n",
    "            for k in range(len(ece_byModel_base_run[i])-1):\n",
    "                file.write('\\t'+str(ece_byModel_base_run[i][k+1])+'\\t'+str(ece_byModel_sig_run[i][k+1])+'\\t'+str(ece_byModel_iso_run[i][k+1]))\n",
    "            file.write('\\n')\n",
    "        # SAVING HYPERPARAMETER\n",
    "        file.write('Hyperparameter\\n')\n",
    "        file.write(generateModelName(models[0][0]))\n",
    "        for i in range(len(models)-1):\n",
    "            file.write('\\t'+generateModelName(models[i+1][0]))\n",
    "        file.write('\\n')\n",
    "        for i in range(len(hyperparam_byModel_run)):\n",
    "            file.write(str(hyperparam_byModel_run[i][0]))\n",
    "            for k in range(len(hyperparam_byModel_run[i])-1):\n",
    "                file.write('\\t'+str(hyperparam_byModel_run[i][k+1]))\n",
    "            file.write('\\n')\n",
    "    finally:\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 1\n",
      "model 1\n",
      "{'min_impurity_decrease': 0.0021295707794572473, 'min_samples_leaf': 31}\n",
      "0.7059043688783897 0.21226326225229017 0.6578066592626596 0.046045949792075117 0.662395900901886 0.0661331136508998\n",
      "model 2\n",
      "{'max_depth': 2}\n",
      "0.7281535785794054 0.08029577534606545 0.7162379835084939 0.05911864588821005 0.7207307429288115 0.08461781145484042\n",
      "model 3\n",
      "{'C': 6.874022853153317, 'penalty': 'l2'}\n",
      "0.8244783590153058 0.10709170132856077 0.8183984315531937 0.05948009355610245 0.8285101415463141 0.16777519074784625\n",
      "model 4\n",
      "{'var_smoothing': 0.9021795070659744}\n",
      "0.8525533265142217 0.2611658510334613 0.8540540132262181 0.14655361276160062 0.8699629237879473 0.22752096986223067\n",
      "model 5\n",
      "{'max_depth': 1}\n",
      "0.6969235256937607 0.07994888076490467 0.7009519743656922 0.09652395062840356 0.7009188637463862 0.07908338585076763\n",
      "model 6\n",
      "{'C': 13.194288618152822, 'penalty': 'l2'}\n",
      "0.8454570855037715 0.28790632103334163 0.8379369435964675 0.21905557447069654 0.8508122308968145 0.2917282717245409\n",
      "model 7\n",
      "{'var_smoothing': 0.882355460260447}\n",
      "0.8508741032529448 0.2540975273335714 0.8536374679183946 0.06983029226817132 0.8713152109567367 0.2523046513234024\n",
      "model 8\n",
      "{'alpha': 8.196181742266363, 'batch_size': 100, 'power_t': 0.9223542489531878}\n",
      "0.8568264318657719 2.581268532253489e-15 0.8551663048971686 0.028689967568244656 0.856695475208868 6.661338147750939e-16\n",
      "run 2\n",
      "model 1\n",
      "{'min_impurity_decrease': 0.010571358564948199, 'min_samples_leaf': 8}\n",
      "0.6676225390951034 0.17544558315958403 0.6341072166622121 0.04522261132973945 0.6288815433520016 0.06194380994894995\n",
      "model 2\n",
      "{'max_depth': 2}\n",
      "0.6834084487632831 0.09096385013541743 0.6966173503260155 0.08719115651300273 0.6858335726038919 0.06543698376760623\n",
      "model 3\n"
     ]
    }
   ],
   "source": [
    "#bs & ece for (b)ase, (s)igmoid and (i)sotonic\n",
    "bs_b, ece_b, bs_s, ece_s, bs_i, ece_i, hyppar = CompareModels(X,y)\n",
    "save_result(dataset_name=dataset_name, nclasses=num_classes, bs_byModel_base_run=bs_b, ece_byModel_base_run=ece_b, bs_byModel_sig_run=bs_s, ece_byModel_sig_run=ece_s, bs_byModel_iso_run=bs_i, ece_byModel_iso_run=ece_i, hyperparam_byModel_run=hyppar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#END_KNN_paramdist = {\n",
    "    #    'weights': ['uniform', 'distance'], \n",
    "    #    'n_neighbors': randint(1,3), \n",
    "    #    'p': randint(1,6)\n",
    "    #}\n",
    "    #models.append((END_KNN(number_of_nds=5, number_of_classes=nclasses, weights='uniform',n_neighbors=3, p=2, generator_String='random_pair', random_state=seed), END_KNN_paramdist))\n",
    "    \n",
    "    # bs_b[run][model]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
